{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "m1pqkWQ53TFh",
        "outputId": "070a405b-7ffb-4945-e9ce-723ddf5dda26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DB_PATH: c:\\Users\\preon\\OneDrive\\Desktop\\final project\\sql-to-ml-pipeline\\data\\classification.db\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Imports\n",
        "# =========================\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import joblib\n",
        "import optuna\n",
        "import mlflow\n",
        "from pathlib import Path\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "REPO_DIR = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "DATA_DIR = REPO_DIR / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "DB_PATH = DATA_DIR / \"classification.db\"\n",
        "\n",
        "print(\"‚úÖ DB_PATH:\", DB_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Paths\n",
        "# =========================\n",
        "REPO_DIR = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "DATA_DIR = REPO_DIR / \"data\"\n",
        "MODELS_DIR = REPO_DIR / \"models\"\n",
        "METRICS_DIR = REPO_DIR / \"metrics\"\n",
        "\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "METRICS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Preprocessing\n",
        "# =========================\n",
        "preprocess = Pipeline([\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Model factory\n",
        "# =========================\n",
        "def make_model(model_name: str):\n",
        "    name = model_name.lower().strip()\n",
        "\n",
        "    if name in [\"ridge\", \"logreg\", \"logistic\"]:\n",
        "        return LogisticRegression(\n",
        "            max_iter=2000,\n",
        "            penalty=\"l2\",\n",
        "            solver=\"lbfgs\"\n",
        "        )\n",
        "\n",
        "    if name in [\"histgradientboosting\", \"hgb\"]:\n",
        "        return HistGradientBoostingClassifier(random_state=42)\n",
        "\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return XGBClassifier(\n",
        "            random_state=42,\n",
        "            eval_metric=\"logloss\",\n",
        "            use_label_encoder=False\n",
        "        )\n",
        "\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return LGBMClassifier(random_state=42)\n",
        "\n",
        "    raise ValueError(f\"Unknown model_name: {model_name}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Pipeline builder\n",
        "# =========================\n",
        "def build_pipeline(model_name: str, use_pca: bool, tuned_params=None):\n",
        "    model = make_model(model_name)\n",
        "\n",
        "    if tuned_params:\n",
        "        model.set_params(**tuned_params)\n",
        "\n",
        "    steps = [(\"preprocess\", preprocess)]\n",
        "\n",
        "    if use_pca:\n",
        "        steps.append((\"pca\", PCA(n_components=0.95, random_state=42)))\n",
        "\n",
        "    steps.append((\"model\", model))\n",
        "\n",
        "    return Pipeline(steps)\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Hyperparameter suggestions\n",
        "# =========================\n",
        "def suggest_params(trial, model_name):\n",
        "    name = model_name.lower()\n",
        "\n",
        "    if name in [\"ridge\", \"logreg\"]:\n",
        "        return {\n",
        "            \"model__C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True)\n",
        "        }\n",
        "\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return {\n",
        "            \"model__n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "            \"model__max_depth\": trial.suggest_int(\"max_depth\", 3, 8)\n",
        "        }\n",
        "\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return {\n",
        "            \"model__n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500)\n",
        "        }\n",
        "\n",
        "    if name in [\"histgradientboosting\", \"hgb\"]:\n",
        "        return {\n",
        "            \"model__max_depth\": trial.suggest_int(\"max_depth\", 3, 10)\n",
        "        }\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "# =========================\n",
        "#Single experiment runner\n",
        "# =========================\n",
        "def run_one_experiment(model_name, use_pca, use_optuna, n_trials=20):\n",
        "    run_name = f\"{model_name}__{'pca' if use_pca else 'no_pca'}__{'optuna' if use_optuna else 'no_optuna'}\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUN:\", run_name)\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    best_params = None\n",
        "\n",
        "    #Optuna \n",
        "    if use_optuna:\n",
        "        def objective(trial):\n",
        "            params = suggest_params(trial, model_name)\n",
        "            pipe = build_pipeline(model_name, use_pca, params)\n",
        "            scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "            return float(np.mean(scores))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_cv_f1 = float(study.best_value)\n",
        "\n",
        "    else:\n",
        "        pipe_tmp = build_pipeline(model_name, use_pca, None)\n",
        "        scores = cross_val_score(pipe_tmp, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "        best_cv_f1 = float(np.mean(scores))\n",
        "\n",
        "    #Train final\n",
        "    pipe = build_pipeline(model_name, use_pca, best_params)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    test_f1 = float(f1_score(y_test, y_pred))\n",
        "\n",
        "    print(\"cv_f1 :\", round(best_cv_f1, 4))\n",
        "    print(\"test_f1:\", round(test_f1, 4))\n",
        "\n",
        "    model_path = MODELS_DIR / f\"{run_name}.joblib\"\n",
        "    metrics_path = METRICS_DIR / f\"{run_name}.json\"\n",
        "\n",
        "    joblib.dump(pipe, model_path)\n",
        "\n",
        "    payload = {\n",
        "        \"run_name\": run_name,\n",
        "        \"model_family\": model_name,\n",
        "        \"uses_pca\": use_pca,\n",
        "        \"uses_optuna\": use_optuna,\n",
        "        \"cv_f1\": best_cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "        \"best_params\": best_params,\n",
        "        \"model_path\": str(model_path),\n",
        "        \"metrics_path\": str(metrics_path),\n",
        "    }\n",
        "\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "\n",
        "    #Log to MLflow (Dagshub)\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        mlflow.log_param(\"model_family\", model_name)\n",
        "        mlflow.log_param(\"uses_pca\", use_pca)\n",
        "        mlflow.log_param(\"uses_optuna\", use_optuna)\n",
        "\n",
        "        if best_params:\n",
        "            mlflow.log_params(best_params)\n",
        "\n",
        "        mlflow.log_metric(\"cv_f1\", best_cv_f1)\n",
        "        mlflow.log_metric(\"test_f1\", test_f1)\n",
        "\n",
        "        mlflow.log_artifact(str(model_path), artifact_path=\"models\")\n",
        "        mlflow.log_artifact(str(metrics_path), artifact_path=\"metrics\")\n",
        "\n",
        "    return payload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTqNkkbR33iG",
        "outputId": "463058a0-4a86-4aa1-b191-dd24eb27442d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Joined df: (569, 32)\n",
            "label\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  mean radius  mean texture  mean perimeter  mean area  \\\n",
              "0       1        17.99         10.38          122.80     1001.0   \n",
              "1       2        20.57         17.77          132.90     1326.0   \n",
              "2       3        19.69         21.25          130.00     1203.0   \n",
              "3       4        11.42         20.38           77.58      386.1   \n",
              "4       5        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   mean symmetry  ...  worst texture  worst perimeter  worst area  \\\n",
              "0         0.2419  ...          17.33           184.60      2019.0   \n",
              "1         0.1812  ...          23.41           158.80      1956.0   \n",
              "2         0.2069  ...          25.53           152.50      1709.0   \n",
              "3         0.2597  ...          26.50            98.87       567.7   \n",
              "4         0.1809  ...          16.67           152.20      1575.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  label  \n",
              "0          0.4601                  0.11890      0  \n",
              "1          0.2750                  0.08902      0  \n",
              "2          0.3613                  0.08758      0  \n",
              "3          0.6638                  0.17300      0  \n",
              "4          0.2364                  0.07678      0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FULL PIPELINE:\n",
        "# - Build preprocessing\n",
        "# - Stratified train/test split\n",
        "# - Train & log 4 models WITHOUT PCA (Ridge, HGB, XGBoost, LightGBM)\n",
        "# - Train & log 4 models WITH PCA (preprocessing + PCA(0.95) + model)\n",
        "# - Pick GLOBAL best among 8 models by Test MAE\n",
        "# - Save, load, and compare the global best model\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "conn = sqlite3.connect(str(DB_PATH))\n",
        "\n",
        "df = pd.read_sql(\"\"\"\n",
        "    SELECT f.*, l.label\n",
        "    FROM features f\n",
        "    JOIN labels l ON f.row_id = l.row_id\n",
        "\"\"\", conn)\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(\"‚úÖ Joined df:\", df.shape)\n",
        "print(df[\"label\"].value_counts())\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Split done:\n",
            "Train: (455, 30) Test: (114, 30)\n",
            "Train label dist:\n",
            " label\n",
            "1    0.626374\n",
            "0    0.373626\n",
            "Name: proportion, dtype: float64\n",
            "Test  label dist:\n",
            " label\n",
            "1    0.631579\n",
            "0    0.368421\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "TARGET_COL = \"label\"\n",
        "ID_COL = \"row_id\"\n",
        "\n",
        "X = df.drop(columns=[TARGET_COL, ID_COL])\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Split done:\")\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
        "print(\"Train label dist:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Test  label dist:\\n\", y_test.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "def make_model(model_name: str):\n",
        "    name = model_name.lower().strip()\n",
        "\n",
        "    if name in [\"logreg\", \"logistic\"]:\n",
        "        return LogisticRegression(\n",
        "            max_iter=2000,\n",
        "            solver=\"lbfgs\"\n",
        "        )\n",
        "\n",
        "    if name in [\"histgradientboosting\", \"hgb\"]:\n",
        "        return HistGradientBoostingClassifier(random_state=42)\n",
        "\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return XGBClassifier(\n",
        "            random_state=42,\n",
        "            eval_metric=\"logloss\",\n",
        "            use_label_encoder=False\n",
        "        )\n",
        "\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return LGBMClassifier(random_state=42)\n",
        "\n",
        "    raise ValueError(f\"Unknown model_name: {model_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def suggest_params(trial, model_name):\n",
        "    name = model_name.lower()\n",
        "\n",
        "    if name in [\"logreg\", \"logistic\"]:\n",
        "        return {\n",
        "            \"model__C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True)\n",
        "        }\n",
        "\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return {\n",
        "            \"model__n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "            \"model__max_depth\": trial.suggest_int(\"max_depth\", 3, 8)\n",
        "        }\n",
        "\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return {\n",
        "            \"model__n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500)\n",
        "        }\n",
        "\n",
        "    if name in [\"histgradientboosting\", \"hgb\"]:\n",
        "        return {\n",
        "            \"model__max_depth\": trial.suggest_int(\"max_depth\", 3, 10)\n",
        "        }\n",
        "\n",
        "    return {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as RamishaPrionti\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as RamishaPrionti\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"RamishaPrionti/sql-to-ml-pipeline\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"RamishaPrionti/sql-to-ml-pipeline\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository RamishaPrionti/sql-to-ml-pipeline initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository RamishaPrionti/sql-to-ml-pipeline initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Imports (safe to repeat)\n",
        "# =========================\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "import joblib\n",
        "import optuna\n",
        "import mlflow\n",
        "import dagshub\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Paths\n",
        "# =========================\n",
        "REPO_DIR = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "MODELS_DIR = REPO_DIR / \"models\"\n",
        "METRICS_DIR = REPO_DIR / \"metrics\"\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "METRICS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Dagshub MLflow init\n",
        "# =========================\n",
        "dagshub.init(repo_owner=\"RamishaPrionti\", repo_name=\"sql-to-ml-pipeline\", mlflow=True)\n",
        "mlflow.set_experiment(\"sql_to_ml_pipeline\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# REQUIRED: preprocess + model factory\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "def make_model(model_name: str):\n",
        "    name = model_name.lower()\n",
        "    if name in [\"logreg\", \"logistic\", \"logistic_regression\"]:\n",
        "        return LogisticRegression(max_iter=2000)\n",
        "    if name in [\"histgradientboosting\", \"hgb\", \"hist_gb\"]:\n",
        "        return HistGradientBoostingClassifier(random_state=42)\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return XGBClassifier(\n",
        "            random_state=42,\n",
        "            eval_metric=\"logloss\",\n",
        "            use_label_encoder=False\n",
        "        )\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return LGBMClassifier(random_state=42)\n",
        "    raise ValueError(f\"Unknown model_name: {model_name}\")\n",
        "\n",
        "\n",
        "def suggest_params(trial, model_name: str):\n",
        "    name = model_name.lower()\n",
        "\n",
        "    if name in [\"logreg\", \"logistic\", \"logistic_regression\"]:\n",
        "        return {\n",
        "            \"C\": trial.suggest_float(\"C\", 1e-3, 10.0, log=True),\n",
        "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
        "        }\n",
        "\n",
        "    if name in [\"histgradientboosting\", \"hgb\", \"hist_gb\"]:\n",
        "        return {\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 400),\n",
        "        }\n",
        "\n",
        "    if name in [\"xgboost\", \"xgb\"]:\n",
        "        return {\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 8),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        }\n",
        "\n",
        "    if name in [\"lightgbm\", \"lgbm\"]:\n",
        "        return {\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
        "        }\n",
        "\n",
        "    raise ValueError(f\"No suggest_params configured for: {model_name}\")\n",
        "\n",
        "\n",
        "\n",
        "def build_pipeline(model_name: str, use_pca: bool, tuned_params: dict | None):\n",
        "    est = make_model(model_name)\n",
        "    if tuned_params:\n",
        "        est.set_params(**tuned_params)\n",
        "\n",
        "    steps = [(\"preprocess\", preprocess)]\n",
        "    if use_pca:\n",
        "        steps.append((\"pca\", PCA(n_components=0.95, random_state=42)))\n",
        "    steps.append((\"model\", est))\n",
        "    return Pipeline(steps)\n",
        "\n",
        "\n",
        "def run_one_experiment(model_name: str, use_pca: bool, use_optuna: bool, n_trials: int = 20):\n",
        "    run_name = f\"{model_name}__{'pca' if use_pca else 'no_pca'}__{'optuna' if use_optuna else 'no_optuna'}\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RUN:\", run_name)\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    best_params = None\n",
        "\n",
        "    #Optuna tuning-\n",
        "    if use_optuna:\n",
        "        def objective(trial):\n",
        "            params = suggest_params(trial, model_name)\n",
        "            pipe = build_pipeline(model_name, use_pca, params)\n",
        "            scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "            return float(np.mean(scores))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_cv_f1 = float(study.best_value)\n",
        "\n",
        "    #No optuna:\n",
        "    else:\n",
        "        pipe_tmp = build_pipeline(model_name, use_pca, tuned_params=None)\n",
        "        scores = cross_val_score(pipe_tmp, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "        best_cv_f1 = float(np.mean(scores))\n",
        "\n",
        "   \n",
        "    pipe = build_pipeline(model_name, use_pca, best_params)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    test_f1 = float(f1_score(y_test, y_pred))\n",
        "\n",
        "    print(\"cv_f1 :\", round(best_cv_f1, 4))\n",
        "    print(\"test_f1:\", round(test_f1, 4))\n",
        "    if best_params:\n",
        "        print(\"best_params:\", best_params)\n",
        "\n",
        "    #Save locally \n",
        "    model_path = MODELS_DIR / f\"{run_name}.joblib\"\n",
        "    metrics_path = METRICS_DIR / f\"{run_name}.json\"\n",
        "    joblib.dump(pipe, model_path)\n",
        "\n",
        "    payload = {\n",
        "        \"run_name\": run_name,\n",
        "        \"model_family\": model_name,\n",
        "        \"uses_pca\": use_pca,\n",
        "        \"uses_optuna\": use_optuna,\n",
        "        \"cv_f1\": best_cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "        \"best_params\": best_params,\n",
        "        \"model_path\": str(model_path),\n",
        "        \"metrics_path\": str(metrics_path),\n",
        "    }\n",
        "\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "\n",
        "    \n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        mlflow.log_param(\"model_family\", model_name)\n",
        "        mlflow.log_param(\"uses_pca\", use_pca)\n",
        "        mlflow.log_param(\"uses_optuna\", use_optuna)\n",
        "        if best_params:\n",
        "            mlflow.log_params(best_params)\n",
        "\n",
        "        mlflow.log_metric(\"cv_f1\", best_cv_f1)\n",
        "        mlflow.log_metric(\"test_f1\", test_f1)\n",
        "\n",
        "        mlflow.log_artifact(str(model_path), artifact_path=\"models\")\n",
        "        mlflow.log_artifact(str(metrics_path), artifact_path=\"metrics\")\n",
        "\n",
        "    return payload \n",
        "\n",
        "\n",
        "def run_all_16():\n",
        "    model_list = [\"logreg\", \"histgradientboosting\", \"xgboost\", \"lightgbm\"]\n",
        "    all_payloads = []\n",
        "    for model_name in model_list:\n",
        "        for use_pca in [False, True]:\n",
        "            for use_optuna in [False, True]:\n",
        "                all_payloads.append(run_one_experiment(model_name, use_pca, use_optuna, n_trials=20))\n",
        "    return all_payloads\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: logreg__no_pca__no_optuna\n",
            "================================================================================\n",
            "cv_f1 : 0.9808\n",
            "test_f1: 0.9861\n",
            "üèÉ View run logreg__no_pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/28efeb3a8b0546bfab2e579bfed7d242\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: logreg__pca__no_optuna\n",
            "================================================================================\n",
            "cv_f1 : 0.9861\n",
            "test_f1: 0.979\n",
            "üèÉ View run logreg__pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/f326a0a5b315437b8781be4bcd70c959\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:30:27,376] A new study created in memory with name: no-name-04bad6be-7179-441e-865e-ff9651289441\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: logreg__no_pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:30:29,162] Trial 0 finished with value: 0.9790558722655804 and parameters: {'C': 1.7479665886752973, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9790558722655804.\n",
            "[I 2025-12-18 12:30:30,832] Trial 1 finished with value: 0.9665244700662009 and parameters: {'C': 0.0034499339772257496, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9790558722655804.\n",
            "[I 2025-12-18 12:30:32,636] Trial 2 finished with value: 0.9755471003357559 and parameters: {'C': 3.813275454197846, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9790558722655804.\n",
            "[I 2025-12-18 12:30:34,399] Trial 3 finished with value: 0.9794508439114478 and parameters: {'C': 0.0394443224261552, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.9794508439114478.\n",
            "[I 2025-12-18 12:30:36,087] Trial 4 finished with value: 0.9755471003357559 and parameters: {'C': 2.394260443576521, 'solver': 'liblinear'}. Best is trial 3 with value: 0.9794508439114478.\n",
            "[I 2025-12-18 12:30:36,112] Trial 5 finished with value: 0.9825101036990865 and parameters: {'C': 0.4442051917188536, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,137] Trial 6 finished with value: 0.9777766875981162 and parameters: {'C': 0.0340391398235402, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,153] Trial 7 finished with value: 0.9808185986156687 and parameters: {'C': 0.6311443125646702, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,177] Trial 8 finished with value: 0.9738205617671122 and parameters: {'C': 4.985007771818707, 'solver': 'liblinear'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,192] Trial 9 finished with value: 0.9810193469603358 and parameters: {'C': 0.07081981767351671, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,209] Trial 10 finished with value: 0.9825101036990865 and parameters: {'C': 0.31930815777917, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,224] Trial 11 finished with value: 0.9825101036990865 and parameters: {'C': 0.3064232146784395, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,240] Trial 12 finished with value: 0.9825101036990865 and parameters: {'C': 0.27428092876255794, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,255] Trial 13 finished with value: 0.9612525280149113 and parameters: {'C': 0.008168661699277633, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,271] Trial 14 finished with value: 0.9825101036990865 and parameters: {'C': 0.4596310666210949, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9825101036990865.\n",
            "[I 2025-12-18 12:30:36,288] Trial 15 finished with value: 0.9827104810996564 and parameters: {'C': 0.12822475443271025, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9827104810996564.\n",
            "[I 2025-12-18 12:30:36,303] Trial 16 finished with value: 0.9645164598502718 and parameters: {'C': 0.01234784002940645, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9827104810996564.\n",
            "[I 2025-12-18 12:30:36,318] Trial 17 finished with value: 0.9827104810996564 and parameters: {'C': 0.10198609624689564, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9827104810996564.\n",
            "[I 2025-12-18 12:30:36,334] Trial 18 finished with value: 0.9598377059516956 and parameters: {'C': 0.001024392846565281, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9827104810996564.\n",
            "[I 2025-12-18 12:30:36,349] Trial 19 finished with value: 0.9827104810996564 and parameters: {'C': 0.1197696356288473, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9827104810996564.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9827\n",
            "test_f1: 0.9793\n",
            "best_params: {'C': 0.12822475443271025, 'solver': 'lbfgs'}\n",
            "üèÉ View run logreg__no_pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/aa7d15d64cb944f1ba764c095f79c4d5\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:30:39,561] A new study created in memory with name: no-name-a8036137-338c-4919-9ce2-dc1aa82144af\n",
            "[I 2025-12-18 12:30:39,597] Trial 0 finished with value: 0.9598377059516956 and parameters: {'C': 0.001198324109281906, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9598377059516956.\n",
            "[I 2025-12-18 12:30:39,632] Trial 1 finished with value: 0.9665244700662009 and parameters: {'C': 0.002527557239748438, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9665244700662009.\n",
            "[I 2025-12-18 12:30:39,668] Trial 2 finished with value: 0.9826559435778414 and parameters: {'C': 2.1780447644018492, 'solver': 'liblinear'}. Best is trial 2 with value: 0.9826559435778414.\n",
            "[I 2025-12-18 12:30:39,703] Trial 3 finished with value: 0.9827463684844776 and parameters: {'C': 0.06649813172177312, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.9827463684844776.\n",
            "[I 2025-12-18 12:30:39,739] Trial 4 finished with value: 0.986146344974002 and parameters: {'C': 0.5626873815011803, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: logreg__pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:30:39,775] Trial 5 finished with value: 0.9826559435778414 and parameters: {'C': 2.2630995839454204, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,811] Trial 6 finished with value: 0.9827463684844776 and parameters: {'C': 0.07843156347234295, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,825] Trial 7 finished with value: 0.9598377059516956 and parameters: {'C': 0.0011863525933701014, 'solver': 'liblinear'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,840] Trial 8 finished with value: 0.9562950808464089 and parameters: {'C': 0.006494709822326531, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,854] Trial 9 finished with value: 0.986146344974002 and parameters: {'C': 0.49765268989001354, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,880] Trial 10 finished with value: 0.986146344974002 and parameters: {'C': 0.4063467545376841, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,896] Trial 11 finished with value: 0.986146344974002 and parameters: {'C': 0.3210092175861442, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,911] Trial 12 finished with value: 0.986146344974002 and parameters: {'C': 0.41285302603200874, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,927] Trial 13 finished with value: 0.9808916980308733 and parameters: {'C': 9.893695438339257, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,943] Trial 14 finished with value: 0.9744104895844347 and parameters: {'C': 0.02834209794725595, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,969] Trial 15 finished with value: 0.9860559082920114 and parameters: {'C': 1.1860488724303055, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:39,985] Trial 16 finished with value: 0.9791101389849164 and parameters: {'C': 5.211216879973627, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:40,011] Trial 17 finished with value: 0.9844375026237984 and parameters: {'C': 0.14887338415302354, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:40,037] Trial 18 finished with value: 0.9772572793239643 and parameters: {'C': 0.016384831915061796, 'solver': 'liblinear'}. Best is trial 4 with value: 0.986146344974002.\n",
            "[I 2025-12-18 12:30:40,066] Trial 19 finished with value: 0.9843644032085935 and parameters: {'C': 0.7984391100455004, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.986146344974002.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9861\n",
            "test_f1: 0.9861\n",
            "best_params: {'C': 0.5626873815011803, 'solver': 'lbfgs'}\n",
            "üèÉ View run logreg__pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/aa245060b9984e7585d66045b93cd6f0\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: hgb__no_pca__no_optuna\n",
            "================================================================================\n",
            "cv_f1 : 0.9757\n",
            "test_f1: 0.9796\n",
            "üèÉ View run hgb__no_pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/f96b5c386dee4fc2966c3cb2821f7b92\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: hgb__pca__no_optuna\n",
            "================================================================================\n",
            "cv_f1 : 0.9703\n",
            "test_f1: 0.9726\n",
            "üèÉ View run hgb__pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/b6b91fdc123c4669a44314a0c4c257b3\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:31:13,362] A new study created in memory with name: no-name-72fe842a-6d00-497e-8e9e-69f06f99bb8f\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: hgb__no_pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:31:13,586] Trial 0 finished with value: 0.9722222222222223 and parameters: {'max_depth': 5, 'learning_rate': 0.025233258312933292, 'max_iter': 233}. Best is trial 0 with value: 0.9722222222222223.\n",
            "[I 2025-12-18 12:31:13,808] Trial 1 finished with value: 0.9773669284467714 and parameters: {'max_depth': 10, 'learning_rate': 0.089889237870699, 'max_iter': 304}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:13,967] Trial 2 finished with value: 0.9756944444444445 and parameters: {'max_depth': 6, 'learning_rate': 0.17187427908158276, 'max_iter': 265}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:14,127] Trial 3 finished with value: 0.9739492437463642 and parameters: {'max_depth': 8, 'learning_rate': 0.04661460903686876, 'max_iter': 110}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:14,338] Trial 4 finished with value: 0.96875 and parameters: {'max_depth': 5, 'learning_rate': 0.024518774749504025, 'max_iter': 214}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:14,540] Trial 5 finished with value: 0.9739492437463642 and parameters: {'max_depth': 4, 'learning_rate': 0.01458294095189747, 'max_iter': 318}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:14,659] Trial 6 finished with value: 0.9773669284467714 and parameters: {'max_depth': 10, 'learning_rate': 0.13779676959058457, 'max_iter': 161}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:14,954] Trial 7 finished with value: 0.9739128853984876 and parameters: {'max_depth': 10, 'learning_rate': 0.022645945056909013, 'max_iter': 347}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,155] Trial 8 finished with value: 0.9756944444444445 and parameters: {'max_depth': 5, 'learning_rate': 0.04001306822280552, 'max_iter': 268}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,325] Trial 9 finished with value: 0.9739853195164075 and parameters: {'max_depth': 5, 'learning_rate': 0.08970139259766371, 'max_iter': 318}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,426] Trial 10 finished with value: 0.9738936611823168 and parameters: {'max_depth': 2, 'learning_rate': 0.25166386539980834, 'max_iter': 375}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,557] Trial 11 finished with value: 0.9739853195164075 and parameters: {'max_depth': 10, 'learning_rate': 0.10975369846051797, 'max_iter': 155}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,699] Trial 12 finished with value: 0.9739853195164075 and parameters: {'max_depth': 8, 'learning_rate': 0.0931615827925182, 'max_iter': 178}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,800] Trial 13 finished with value: 0.9756944444444445 and parameters: {'max_depth': 8, 'learning_rate': 0.15583509243502874, 'max_iter': 113}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:15,964] Trial 14 finished with value: 0.9756944444444445 and parameters: {'max_depth': 9, 'learning_rate': 0.06851534516397412, 'max_iter': 183}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:16,054] Trial 15 finished with value: 0.9756944444444445 and parameters: {'max_depth': 10, 'learning_rate': 0.2823125736886967, 'max_iter': 297}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:16,226] Trial 16 finished with value: 0.9756944444444445 and parameters: {'max_depth': 7, 'learning_rate': 0.12584031204719454, 'max_iter': 388}. Best is trial 1 with value: 0.9773669284467714.\n",
            "[I 2025-12-18 12:31:16,328] Trial 17 finished with value: 0.9774935233160621 and parameters: {'max_depth': 9, 'learning_rate': 0.19238671419468334, 'max_iter': 142}. Best is trial 17 with value: 0.9774935233160621.\n",
            "[I 2025-12-18 12:31:16,430] Trial 18 finished with value: 0.9756944444444445 and parameters: {'max_depth': 9, 'learning_rate': 0.21067773589414446, 'max_iter': 215}. Best is trial 17 with value: 0.9774935233160621.\n",
            "[I 2025-12-18 12:31:16,633] Trial 19 finished with value: 0.9756944444444445 and parameters: {'max_depth': 9, 'learning_rate': 0.06791769073113808, 'max_iter': 272}. Best is trial 17 with value: 0.9774935233160621.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9775\n",
            "test_f1: 0.966\n",
            "best_params: {'max_depth': 9, 'learning_rate': 0.19238671419468334, 'max_iter': 142}\n",
            "üèÉ View run hgb__no_pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/be71c54027c44b67a4c34f0db6b9e2f6\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:31:25,365] A new study created in memory with name: no-name-28abe956-045a-4b48-94ff-fc3a22197386\n",
            "[I 2025-12-18 12:31:25,442] Trial 0 finished with value: 0.9440773920617146 and parameters: {'max_depth': 8, 'learning_rate': 0.014436443989050446, 'max_iter': 115}. Best is trial 0 with value: 0.9440773920617146.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: hgb__pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:31:25,571] Trial 1 finished with value: 0.9685672514619883 and parameters: {'max_depth': 6, 'learning_rate': 0.041846122157524986, 'max_iter': 257}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:25,648] Trial 2 finished with value: 0.966909057437408 and parameters: {'max_depth': 6, 'learning_rate': 0.2739420508491107, 'max_iter': 266}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:25,725] Trial 3 finished with value: 0.9651087421008797 and parameters: {'max_depth': 9, 'learning_rate': 0.2145870578457951, 'max_iter': 228}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:25,781] Trial 4 finished with value: 0.9634398766778777 and parameters: {'max_depth': 2, 'learning_rate': 0.03623113414786745, 'max_iter': 184}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:25,878] Trial 5 finished with value: 0.9509134480568301 and parameters: {'max_depth': 3, 'learning_rate': 0.01138586325258387, 'max_iter': 275}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:25,935] Trial 6 finished with value: 0.9493686798361244 and parameters: {'max_depth': 3, 'learning_rate': 0.025376945378805596, 'max_iter': 111}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,011] Trial 7 finished with value: 0.9684377799015671 and parameters: {'max_depth': 6, 'learning_rate': 0.16652738404210132, 'max_iter': 155}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,068] Trial 8 finished with value: 0.9403508771929824 and parameters: {'max_depth': 2, 'learning_rate': 0.012986137514524302, 'max_iter': 180}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,138] Trial 9 finished with value: 0.9493337765589075 and parameters: {'max_depth': 6, 'learning_rate': 0.015376600368781402, 'max_iter': 126}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,280] Trial 10 finished with value: 0.9667646365509626 and parameters: {'max_depth': 5, 'learning_rate': 0.08740101259253884, 'max_iter': 383}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,422] Trial 11 finished with value: 0.9667646365509626 and parameters: {'max_depth': 7, 'learning_rate': 0.08474531304716987, 'max_iter': 345}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,533] Trial 12 finished with value: 0.9667646365509626 and parameters: {'max_depth': 10, 'learning_rate': 0.13768830135518156, 'max_iter': 312}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,634] Trial 13 finished with value: 0.9685672514619883 and parameters: {'max_depth': 5, 'learning_rate': 0.04864904506671036, 'max_iter': 192}. Best is trial 1 with value: 0.9685672514619883.\n",
            "[I 2025-12-18 12:31:26,735] Trial 14 finished with value: 0.9686211296355257 and parameters: {'max_depth': 4, 'learning_rate': 0.04666193886174426, 'max_iter': 217}. Best is trial 14 with value: 0.9686211296355257.\n",
            "[I 2025-12-18 12:31:26,835] Trial 15 finished with value: 0.9653118871556826 and parameters: {'max_depth': 4, 'learning_rate': 0.027094559174764492, 'max_iter': 222}. Best is trial 14 with value: 0.9686211296355257.\n",
            "[I 2025-12-18 12:31:26,958] Trial 16 finished with value: 0.9702942729861302 and parameters: {'max_depth': 4, 'learning_rate': 0.07418190862950527, 'max_iter': 285}. Best is trial 16 with value: 0.9702942729861302.\n",
            "[I 2025-12-18 12:31:27,080] Trial 17 finished with value: 0.9686211296355257 and parameters: {'max_depth': 4, 'learning_rate': 0.07827965769630152, 'max_iter': 305}. Best is trial 16 with value: 0.9702942729861302.\n",
            "[I 2025-12-18 12:31:27,201] Trial 18 finished with value: 0.9702942729861302 and parameters: {'max_depth': 4, 'learning_rate': 0.06369522944358627, 'max_iter': 307}. Best is trial 16 with value: 0.9702942729861302.\n",
            "[I 2025-12-18 12:31:27,311] Trial 19 finished with value: 0.9667646365509626 and parameters: {'max_depth': 3, 'learning_rate': 0.1243119341446537, 'max_iter': 393}. Best is trial 16 with value: 0.9702942729861302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9703\n",
            "test_f1: 0.9722\n",
            "best_params: {'max_depth': 4, 'learning_rate': 0.07418190862950527, 'max_iter': 285}\n",
            "üèÉ View run hgb__pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/60e5cd9391ae4e3cb3f41b2fe3e28683\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: xgb__no_pca__no_optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [12:31:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.972\n",
            "test_f1: 0.966\n",
            "üèÉ View run xgb__no_pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/75ec9023d2f44c72bb9955c7836ac4ac\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: xgb__pca__no_optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [12:31:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9581\n",
            "test_f1: 0.9583\n",
            "üèÉ View run xgb__pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/ed516ab561f94348bfd5f7dfde8259ea\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:31:59,442] A new study created in memory with name: no-name-58df846a-221f-4ee7-a724-214ee208a382\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: xgb__no_pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:32:00,163] Trial 0 finished with value: 0.9737665863320313 and parameters: {'n_estimators': 389, 'max_depth': 5, 'learning_rate': 0.08946172648484138, 'subsample': 0.9803170072110121, 'colsample_bytree': 0.6985202156915373}. Best is trial 0 with value: 0.9737665863320313.\n",
            "[I 2025-12-18 12:32:00,600] Trial 1 finished with value: 0.9753829016986911 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.09068251864886465, 'subsample': 0.6089919198760088, 'colsample_bytree': 0.7787887593784977}. Best is trial 1 with value: 0.9753829016986911.\n",
            "[I 2025-12-18 12:32:01,058] Trial 2 finished with value: 0.9755116959064326 and parameters: {'n_estimators': 327, 'max_depth': 2, 'learning_rate': 0.028448822504454303, 'subsample': 0.9547566055339936, 'colsample_bytree': 0.6212421804729961}. Best is trial 2 with value: 0.9755116959064326.\n",
            "[I 2025-12-18 12:32:01,530] Trial 3 finished with value: 0.973729462545252 and parameters: {'n_estimators': 243, 'max_depth': 4, 'learning_rate': 0.06389003017024082, 'subsample': 0.9512587021401141, 'colsample_bytree': 0.6396970045657024}. Best is trial 2 with value: 0.9755116959064326.\n",
            "[I 2025-12-18 12:32:01,931] Trial 4 finished with value: 0.9737665863320313 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.05408159707542438, 'subsample': 0.7132435138771973, 'colsample_bytree': 0.6744275858699154}. Best is trial 2 with value: 0.9755116959064326.\n",
            "[I 2025-12-18 12:32:02,095] Trial 5 finished with value: 0.966876102292769 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.02035731215601465, 'subsample': 0.8043864285128554, 'colsample_bytree': 0.8152431207702232}. Best is trial 2 with value: 0.9755116959064326.\n",
            "[I 2025-12-18 12:32:02,332] Trial 6 finished with value: 0.9755488196932122 and parameters: {'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.023642973696559492, 'subsample': 0.7001004533685262, 'colsample_bytree': 0.7615115515356911}. Best is trial 6 with value: 0.9755488196932122.\n",
            "[I 2025-12-18 12:32:02,488] Trial 7 finished with value: 0.9807660512537889 and parameters: {'n_estimators': 375, 'max_depth': 4, 'learning_rate': 0.09766889359841921, 'subsample': 0.7774005342262872, 'colsample_bytree': 0.6344853645790139}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:02,766] Trial 8 finished with value: 0.9789838178926082 and parameters: {'n_estimators': 391, 'max_depth': 7, 'learning_rate': 0.022625382207565794, 'subsample': 0.7281908882050369, 'colsample_bytree': 0.6616934655248496}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:02,940] Trial 9 finished with value: 0.979093567251462 and parameters: {'n_estimators': 419, 'max_depth': 3, 'learning_rate': 0.0662753738421097, 'subsample': 0.8440453667338514, 'colsample_bytree': 0.6791354806938745}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:03,113] Trial 10 finished with value: 0.9773281794007183 and parameters: {'n_estimators': 499, 'max_depth': 8, 'learning_rate': 0.2972514523570044, 'subsample': 0.8862311268575164, 'colsample_bytree': 0.9464142856026371}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:03,286] Trial 11 finished with value: 0.9789838178926082 and parameters: {'n_estimators': 496, 'max_depth': 3, 'learning_rate': 0.14914684918898896, 'subsample': 0.8290689922768548, 'colsample_bytree': 0.7259482233914312}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:03,503] Trial 12 finished with value: 0.9755847953216374 and parameters: {'n_estimators': 414, 'max_depth': 3, 'learning_rate': 0.04471229323663034, 'subsample': 0.8472598443371656, 'colsample_bytree': 0.603056138264777}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:03,749] Trial 13 finished with value: 0.9702761849358708 and parameters: {'n_estimators': 434, 'max_depth': 2, 'learning_rate': 0.01067515703044132, 'subsample': 0.7652906027311168, 'colsample_bytree': 0.8627194897051511}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:03,888] Trial 14 finished with value: 0.9772015845314274 and parameters: {'n_estimators': 321, 'max_depth': 4, 'learning_rate': 0.15903485549309224, 'subsample': 0.8925277476530765, 'colsample_bytree': 0.7236362343438829}. Best is trial 7 with value: 0.9807660512537889.\n",
            "[I 2025-12-18 12:32:04,048] Trial 15 finished with value: 0.9825296224855332 and parameters: {'n_estimators': 356, 'max_depth': 3, 'learning_rate': 0.12427059402228852, 'subsample': 0.6618627346375019, 'colsample_bytree': 0.9931622879799042}. Best is trial 15 with value: 0.9825296224855332.\n",
            "[I 2025-12-18 12:32:04,202] Trial 16 finished with value: 0.982564644195405 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.18876524433412858, 'subsample': 0.6268641323145365, 'colsample_bytree': 0.9798069526028677}. Best is trial 16 with value: 0.982564644195405.\n",
            "[I 2025-12-18 12:32:04,314] Trial 17 finished with value: 0.9686218801074822 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.2994473546617409, 'subsample': 0.6024591685527521, 'colsample_bytree': 0.9925341667799885}. Best is trial 16 with value: 0.982564644195405.\n",
            "[I 2025-12-18 12:32:04,431] Trial 18 finished with value: 0.9861104487883301 and parameters: {'n_estimators': 197, 'max_depth': 3, 'learning_rate': 0.17767326614393697, 'subsample': 0.6564908050297785, 'colsample_bytree': 0.904573744078116}. Best is trial 18 with value: 0.9861104487883301.\n",
            "[I 2025-12-18 12:32:04,536] Trial 19 finished with value: 0.9773113338902814 and parameters: {'n_estimators': 178, 'max_depth': 2, 'learning_rate': 0.18649833806754304, 'subsample': 0.6510923357274574, 'colsample_bytree': 0.9123803237158219}. Best is trial 18 with value: 0.9861104487883301.\n",
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [12:32:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9861\n",
            "test_f1: 0.966\n",
            "best_params: {'n_estimators': 197, 'max_depth': 3, 'learning_rate': 0.17767326614393697, 'subsample': 0.6564908050297785, 'colsample_bytree': 0.904573744078116}\n",
            "üèÉ View run xgb__no_pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/7cba0763cccc421da4623076ae816611\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:32:11,364] A new study created in memory with name: no-name-0e99a870-665c-4d0e-aec9-e3b588c6195d\n",
            "[I 2025-12-18 12:32:11,477] Trial 0 finished with value: 0.9474018172777062 and parameters: {'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.01052219845864629, 'subsample': 0.6962206835554969, 'colsample_bytree': 0.6027872264354704}. Best is trial 0 with value: 0.9474018172777062.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: xgb__pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:32:11,673] Trial 1 finished with value: 0.9667646365509626 and parameters: {'n_estimators': 358, 'max_depth': 7, 'learning_rate': 0.02141372392940984, 'subsample': 0.7325119181819089, 'colsample_bytree': 0.603297229312715}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:11,777] Trial 2 finished with value: 0.9631613720158257 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.061740789098894376, 'subsample': 0.73922358642428, 'colsample_bytree': 0.943294157278555}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:11,877] Trial 3 finished with value: 0.9581747847538201 and parameters: {'n_estimators': 210, 'max_depth': 8, 'learning_rate': 0.12217737610432076, 'subsample': 0.8018438917993561, 'colsample_bytree': 0.7750915896420594}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:11,995] Trial 4 finished with value: 0.9648883935399676 and parameters: {'n_estimators': 294, 'max_depth': 3, 'learning_rate': 0.0475550578339234, 'subsample': 0.6965405052218526, 'colsample_bytree': 0.7681321132524526}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,226] Trial 5 finished with value: 0.9596914950973673 and parameters: {'n_estimators': 366, 'max_depth': 6, 'learning_rate': 0.010807031496600067, 'subsample': 0.7021467886663282, 'colsample_bytree': 0.9868155252554027}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,326] Trial 6 finished with value: 0.9580690514489044 and parameters: {'n_estimators': 286, 'max_depth': 8, 'learning_rate': 0.10703190403659923, 'subsample': 0.7377005382616113, 'colsample_bytree': 0.7527420845118836}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,426] Trial 7 finished with value: 0.9532733700272967 and parameters: {'n_estimators': 106, 'max_depth': 7, 'learning_rate': 0.020466117731218227, 'subsample': 0.9134276931042754, 'colsample_bytree': 0.7409199893667241}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,524] Trial 8 finished with value: 0.9581493543423706 and parameters: {'n_estimators': 244, 'max_depth': 3, 'learning_rate': 0.011823519988608724, 'subsample': 0.780011991757765, 'colsample_bytree': 0.7743001869483975}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,677] Trial 9 finished with value: 0.9598665666484817 and parameters: {'n_estimators': 475, 'max_depth': 6, 'learning_rate': 0.07347701316126597, 'subsample': 0.9041126068711454, 'colsample_bytree': 0.9228067323780371}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:12,840] Trial 10 finished with value: 0.9650376150268206 and parameters: {'n_estimators': 403, 'max_depth': 5, 'learning_rate': 0.02795565558864233, 'subsample': 0.6035150699496655, 'colsample_bytree': 0.6081118582115917}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,007] Trial 11 finished with value: 0.9651087421008797 and parameters: {'n_estimators': 404, 'max_depth': 5, 'learning_rate': 0.02480977772889315, 'subsample': 0.6092554610779888, 'colsample_bytree': 0.6006989704331009}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,108] Trial 12 finished with value: 0.9546545777272105 and parameters: {'n_estimators': 396, 'max_depth': 4, 'learning_rate': 0.28436789213863956, 'subsample': 0.6325566270715424, 'colsample_bytree': 0.6734943053768816}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,338] Trial 13 finished with value: 0.9667646365509626 and parameters: {'n_estimators': 496, 'max_depth': 6, 'learning_rate': 0.02530401891845349, 'subsample': 0.83764393861664, 'colsample_bytree': 0.678557348604885}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,548] Trial 14 finished with value: 0.9633104051174565 and parameters: {'n_estimators': 494, 'max_depth': 7, 'learning_rate': 0.03422167019411896, 'subsample': 0.8447551124488064, 'colsample_bytree': 0.6682773315107019}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,800] Trial 15 finished with value: 0.9600510277648148 and parameters: {'n_estimators': 459, 'max_depth': 6, 'learning_rate': 0.01770536159330277, 'subsample': 0.9808529294012863, 'colsample_bytree': 0.6824369345416421}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:13,986] Trial 16 finished with value: 0.963232499089885 and parameters: {'n_estimators': 336, 'max_depth': 7, 'learning_rate': 0.0388625591950307, 'subsample': 0.8441597776589054, 'colsample_bytree': 0.843979263547628}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:14,114] Trial 17 finished with value: 0.963232499089885 and parameters: {'n_estimators': 440, 'max_depth': 2, 'learning_rate': 0.015575221831404406, 'subsample': 0.8447721400052415, 'colsample_bytree': 0.6981235364570002}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:14,286] Trial 18 finished with value: 0.9613425889470427 and parameters: {'n_estimators': 222, 'max_depth': 6, 'learning_rate': 0.027921454585453497, 'subsample': 0.798025418936247, 'colsample_bytree': 0.8429149543268304}. Best is trial 1 with value: 0.9667646365509626.\n",
            "[I 2025-12-18 12:32:14,445] Trial 19 finished with value: 0.9565112652089555 and parameters: {'n_estimators': 167, 'max_depth': 7, 'learning_rate': 0.015740404930409856, 'subsample': 0.9079424105551187, 'colsample_bytree': 0.6377980537650392}. Best is trial 1 with value: 0.9667646365509626.\n",
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [12:32:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_f1 : 0.9668\n",
            "test_f1: 0.9655\n",
            "best_params: {'n_estimators': 358, 'max_depth': 7, 'learning_rate': 0.02141372392940984, 'subsample': 0.7325119181819089, 'colsample_bytree': 0.603297229312715}\n",
            "üèÉ View run xgb__pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/410865e7982b49ba9b3b1a17d5f724ee\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: lgbm__no_pca__no_optuna\n",
            "================================================================================\n",
            "[LightGBM] [Info] Number of positive: 285, number of negative: 170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4545\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626374 -> initscore=0.516691\n",
            "[LightGBM] [Info] Start training from score 0.516691\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "cv_f1 : 0.9757\n",
            "test_f1: 0.966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run lgbm__no_pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/3bc4dbbfa6cf490baa72078955dd5dee\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: lgbm__pca__no_optuna\n",
            "================================================================================\n",
            "[LightGBM] [Info] Number of positive: 285, number of negative: 170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1520\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626374 -> initscore=0.516691\n",
            "[LightGBM] [Info] Start training from score 0.516691\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "cv_f1 : 0.9669\n",
            "test_f1: 0.9793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run lgbm__pca__no_optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/61fdefbc29d64148bf8f47b304559fff\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:32:45,391] A new study created in memory with name: no-name-3f8eb5db-ecfd-4003-84ec-2dfce2bdacd1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RUN: lgbm__no_pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:32:47,241] Trial 0 finished with value: 0.9757287333453909 and parameters: {'n_estimators': 320, 'max_depth': 1, 'learning_rate': 0.019243902032649505, 'num_leaves': 115}. Best is trial 0 with value: 0.9757287333453909.\n",
            "[I 2025-12-18 12:32:49,101] Trial 1 finished with value: 0.980857329842932 and parameters: {'n_estimators': 454, 'max_depth': 8, 'learning_rate': 0.2320859975356283, 'num_leaves': 22}. Best is trial 1 with value: 0.980857329842932.\n",
            "[I 2025-12-18 12:32:50,876] Trial 2 finished with value: 0.9808755090168703 and parameters: {'n_estimators': 255, 'max_depth': 0, 'learning_rate': 0.2791025290956269, 'num_leaves': 65}. Best is trial 2 with value: 0.9808755090168703.\n",
            "[I 2025-12-18 12:32:52,763] Trial 3 finished with value: 0.9791121291448516 and parameters: {'n_estimators': 380, 'max_depth': 6, 'learning_rate': 0.14836494551426224, 'num_leaves': 87}. Best is trial 2 with value: 0.9808755090168703.\n",
            "[I 2025-12-18 12:32:54,688] Trial 4 finished with value: 0.9738581565169468 and parameters: {'n_estimators': 483, 'max_depth': 3, 'learning_rate': 0.015589298420208607, 'num_leaves': 69}. Best is trial 2 with value: 0.9808755090168703.\n",
            "[I 2025-12-18 12:32:54,817] Trial 5 finished with value: 0.9842931937172775 and parameters: {'n_estimators': 172, 'max_depth': 4, 'learning_rate': 0.26576135368282805, 'num_leaves': 123}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:54,977] Trial 6 finished with value: 0.9825661721931356 and parameters: {'n_estimators': 214, 'max_depth': 5, 'learning_rate': 0.19019461703644525, 'num_leaves': 117}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:55,613] Trial 7 finished with value: 0.97402130109384 and parameters: {'n_estimators': 476, 'max_depth': 12, 'learning_rate': 0.02439029117954601, 'num_leaves': 78}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:55,968] Trial 8 finished with value: 0.9756399069226295 and parameters: {'n_estimators': 282, 'max_depth': -1, 'learning_rate': 0.015111357838582222, 'num_leaves': 105}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:56,417] Trial 9 finished with value: 0.9808027923211169 and parameters: {'n_estimators': 416, 'max_depth': 7, 'learning_rate': 0.0487029744445305, 'num_leaves': 98}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:56,679] Trial 10 finished with value: 0.9774032867946479 and parameters: {'n_estimators': 134, 'max_depth': 12, 'learning_rate': 0.09274161178252331, 'num_leaves': 128}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:56,826] Trial 11 finished with value: 0.979075770796975 and parameters: {'n_estimators': 165, 'max_depth': 3, 'learning_rate': 0.11952094247320062, 'num_leaves': 125}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,025] Trial 12 finished with value: 0.9774389857942473 and parameters: {'n_estimators': 202, 'max_depth': 4, 'learning_rate': 0.055819781592025206, 'num_leaves': 51}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,204] Trial 13 finished with value: 0.9808755090168703 and parameters: {'n_estimators': 208, 'max_depth': 9, 'learning_rate': 0.20214392689465135, 'num_leaves': 104}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,360] Trial 14 finished with value: 0.9722579212218214 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.07420315997386003, 'num_leaves': 114}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,488] Trial 15 finished with value: 0.9773851076207097 and parameters: {'n_estimators': 237, 'max_depth': 2, 'learning_rate': 0.1646579029448984, 'num_leaves': 90}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,677] Trial 16 finished with value: 0.9825661721931356 and parameters: {'n_estimators': 324, 'max_depth': 10, 'learning_rate': 0.29444074012002464, 'num_leaves': 52}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:57,864] Trial 17 finished with value: 0.9790939499709133 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.11127078178878275, 'num_leaves': 116}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:58,104] Trial 18 finished with value: 0.9757119642701052 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.03538883416059511, 'num_leaves': 128}. Best is trial 5 with value: 0.9842931937172775.\n",
            "[I 2025-12-18 12:32:58,251] Trial 19 finished with value: 0.980857329842932 and parameters: {'n_estimators': 215, 'max_depth': 3, 'learning_rate': 0.1786209827109802, 'num_leaves': 32}. Best is trial 5 with value: 0.9842931937172775.\n",
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 285, number of negative: 170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4545\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626374 -> initscore=0.516691\n",
            "[LightGBM] [Info] Start training from score 0.516691\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "cv_f1 : 0.9843\n",
            "test_f1: 0.9726\n",
            "best_params: {'n_estimators': 172, 'max_depth': 4, 'learning_rate': 0.26576135368282805, 'num_leaves': 123}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:33:00,985] A new study created in memory with name: no-name-718472f9-eb9f-4a97-9e86-60d8fa27cc99\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run lgbm__no_pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/d13f835d8b97423eb6896ce45ce651df\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "================================================================================\n",
            "RUN: lgbm__pca__optuna\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 12:33:01,064] Trial 0 finished with value: 0.9599714008361504 and parameters: {'n_estimators': 184, 'max_depth': 2, 'learning_rate': 0.26357932650032845, 'num_leaves': 23}. Best is trial 0 with value: 0.9599714008361504.\n",
            "[I 2025-12-18 12:33:01,256] Trial 1 finished with value: 0.9597071405823198 and parameters: {'n_estimators': 166, 'max_depth': 6, 'learning_rate': 0.026204883481624665, 'num_leaves': 41}. Best is trial 0 with value: 0.9599714008361504.\n",
            "[I 2025-12-18 12:33:01,572] Trial 2 finished with value: 0.95453216374269 and parameters: {'n_estimators': 269, 'max_depth': 9, 'learning_rate': 0.012089509782912766, 'num_leaves': 54}. Best is trial 0 with value: 0.9599714008361504.\n",
            "[I 2025-12-18 12:33:02,004] Trial 3 finished with value: 0.9653292678558637 and parameters: {'n_estimators': 327, 'max_depth': 8, 'learning_rate': 0.03918882962106877, 'num_leaves': 81}. Best is trial 3 with value: 0.9653292678558637.\n",
            "[I 2025-12-18 12:33:02,155] Trial 4 finished with value: 0.9528726359618022 and parameters: {'n_estimators': 352, 'max_depth': 2, 'learning_rate': 0.014152775842640833, 'num_leaves': 111}. Best is trial 3 with value: 0.9653292678558637.\n",
            "[I 2025-12-18 12:33:02,419] Trial 5 finished with value: 0.9653864331002202 and parameters: {'n_estimators': 193, 'max_depth': 7, 'learning_rate': 0.07327810205177834, 'num_leaves': 108}. Best is trial 5 with value: 0.9653864331002202.\n",
            "[I 2025-12-18 12:33:02,899] Trial 6 finished with value: 0.9634698311836183 and parameters: {'n_estimators': 481, 'max_depth': 6, 'learning_rate': 0.011699844719814077, 'num_leaves': 76}. Best is trial 5 with value: 0.9653864331002202.\n",
            "[I 2025-12-18 12:33:03,265] Trial 7 finished with value: 0.9653292678558637 and parameters: {'n_estimators': 281, 'max_depth': 11, 'learning_rate': 0.04729628820210854, 'num_leaves': 36}. Best is trial 5 with value: 0.9653864331002202.\n",
            "[I 2025-12-18 12:33:03,726] Trial 8 finished with value: 0.9688104302634759 and parameters: {'n_estimators': 368, 'max_depth': 11, 'learning_rate': 0.03532542019021317, 'num_leaves': 30}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:04,072] Trial 9 finished with value: 0.9653292678558637 and parameters: {'n_estimators': 344, 'max_depth': 0, 'learning_rate': 0.05856559223944628, 'num_leaves': 73}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:04,348] Trial 10 finished with value: 0.9652927181482612 and parameters: {'n_estimators': 441, 'max_depth': 12, 'learning_rate': 0.12055515308552579, 'num_leaves': 16}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:04,525] Trial 11 finished with value: 0.9637790696838117 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.10148151498682165, 'num_leaves': 125}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:04,785] Trial 12 finished with value: 0.9637219044394549 and parameters: {'n_estimators': 208, 'max_depth': 10, 'learning_rate': 0.09431438886834381, 'num_leaves': 94}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:05,234] Trial 13 finished with value: 0.9668026245233788 and parameters: {'n_estimators': 401, 'max_depth': 7, 'learning_rate': 0.023988479889812123, 'num_leaves': 101}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:05,557] Trial 14 finished with value: 0.9670562893800057 and parameters: {'n_estimators': 404, 'max_depth': 4, 'learning_rate': 0.024878593512366418, 'num_leaves': 57}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:05,859] Trial 15 finished with value: 0.9638576361813523 and parameters: {'n_estimators': 407, 'max_depth': 4, 'learning_rate': 0.026265809152099428, 'num_leaves': 56}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:06,233] Trial 16 finished with value: 0.96529587645208 and parameters: {'n_estimators': 496, 'max_depth': 4, 'learning_rate': 0.018997282793694566, 'num_leaves': 52}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:06,701] Trial 17 finished with value: 0.963565887983845 and parameters: {'n_estimators': 386, 'max_depth': -1, 'learning_rate': 0.03681567883193909, 'num_leaves': 36}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:07,056] Trial 18 finished with value: 0.9634185297687257 and parameters: {'n_estimators': 443, 'max_depth': 4, 'learning_rate': 0.020519538961034155, 'num_leaves': 65}. Best is trial 8 with value: 0.9688104302634759.\n",
            "[I 2025-12-18 12:33:07,184] Trial 19 finished with value: 0.9649490369638993 and parameters: {'n_estimators': 243, 'max_depth': 2, 'learning_rate': 0.15827441622993732, 'num_leaves': 28}. Best is trial 8 with value: 0.9688104302634759.\n",
            "c:\\Users\\preon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 285, number of negative: 170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1520\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626374 -> initscore=0.516691\n",
            "[LightGBM] [Info] Start training from score 0.516691\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "cv_f1 : 0.9688\n",
            "test_f1: 0.9863\n",
            "best_params: {'n_estimators': 368, 'max_depth': 11, 'learning_rate': 0.03532542019021317, 'num_leaves': 30}\n",
            "üèÉ View run lgbm__pca__optuna at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0/runs/8f2c5157da3e4772b370fd93211c9dfd\n",
            "üß™ View experiment at: https://dagshub.com/RamishaPrionti/sql-to-ml-pipeline.mlflow/#/experiments/0\n",
            "\n",
            "‚úÖ DONE. Total runs: 16\n",
            "Elapsed minutes: 2.97\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAMES = [\"logreg\", \"hgb\", \"xgb\", \"lgbm\"]\n",
        "all_runs = []\n",
        "start = time.time()\n",
        "\n",
        "for model_name in MODEL_NAMES:\n",
        "    all_runs.append(run_one_experiment(model_name, use_pca=False, use_optuna=False))\n",
        "    all_runs.append(run_one_experiment(model_name, use_pca=True,  use_optuna=False))\n",
        "    all_runs.append(run_one_experiment(model_name, use_pca=False, use_optuna=True, n_trials=20))\n",
        "    all_runs.append(run_one_experiment(model_name, use_pca=True,  use_optuna=True, n_trials=20))\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(\"\\n‚úÖ DONE. Total runs:\", len(all_runs))\n",
        "print(\"Elapsed minutes:\", round(elapsed/60, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ BEST RUN: lgbm__pca__optuna\n",
            "Best test_f1: 0.9863013698630136\n",
            "‚úÖ Saved FINAL model to: c:\\Users\\preon\\OneDrive\\Desktop\\final project\\sql-to-ml-pipeline\\models\\final_model.joblib\n"
          ]
        }
      ],
      "source": [
        "best = results_df.iloc[0].to_dict()\n",
        "\n",
        "print(\"‚úÖ BEST RUN:\", best[\"run_name\"])\n",
        "print(\"Best test_f1:\", best[\"test_f1\"])\n",
        "\n",
        "best_model = joblib.load(best[\"model_path\"])\n",
        "\n",
        "FINAL_MODEL_PATH = MODELS_DIR / \"final_model.joblib\"\n",
        "joblib.dump(best_model, FINAL_MODEL_PATH)\n",
        "\n",
        "print(\"‚úÖ Saved FINAL model to:\", FINAL_MODEL_PATH)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
